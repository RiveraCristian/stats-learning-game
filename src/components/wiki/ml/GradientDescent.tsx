import React from 'react';
import { ArticleLayout } from '../common/ArticleLayout';
import { Section } from '../common/Section';
import { Example } from '../common/Example';
import { KeyConcept } from '../common/KeyConcept';
import { CodeBlock } from '../common/CodeBlock';
import { TrendingDown, Mountain, Compass } from 'lucide-react';

export const GradientDescent: React.FC = () => {
    return (
        <ArticleLayout category="ml">
            <div className="text-center mb-12">
                <h1 className="text-4xl md:text-5xl font-bold bg-gradient-to-r from-green-500 to-teal-500 bg-clip-text text-transparent mb-4">
                    Gradient Descent
                </h1>
                <p className="text-xl text-gray-600 dark:text-gray-400">
                    El motor que impulsa el aprendizaje de las redes neuronales
                </p>
            </div>

            <Section title="La Met√°fora de la Monta√±a" icon={<Mountain />}>
                <div className="relative h-48 bg-gradient-to-b from-blue-100 to-green-100 dark:from-slate-800 dark:to-slate-900 rounded-lg overflow-hidden mb-6 flex items-center justify-center">
                    {/* Visual metaphor placeholder */}
                    <div className="text-center">
                        <p className="text-4xl mb-2">üèîÔ∏è üèÉ</p>
                        <p className="text-sm text-gray-600 dark:text-gray-400">Objetivo: Llegar al valle (m√≠nimo error)</p>
                    </div>
                </div>
                <p className="text-lg leading-relaxed mb-4">
                    Imagina que est√°s en la cima de una monta√±a en medio de una densa niebla. No puedes ver el valle abajo,
                    pero quieres llegar all√≠ lo m√°s r√°pido posible.
                </p>
                <p className="mb-4">
                    ¬øQu√© haces? Miras a tu alrededor, sientes la pendiente bajo tus pies y das un paso en la direcci√≥n
                    donde el terreno desciende m√°s pronunciadamente. Repites esto una y otra vez hasta llegar al fondo.
                    Eso es exactamente lo que hace el <strong>Descenso de Gradiente</strong>.
                </p>
            </Section>

            <Section title="¬øC√≥mo funciona?" icon={<TrendingDown />}>
                <ol className="list-decimal list-inside space-y-4 ml-4">
                    <li>
                        <strong>Inicializaci√≥n:</strong> Empezamos con valores aleatorios para los par√°metros del modelo (pesos).
                    </li>
                    <li>
                        <strong>C√°lculo del Error (Loss):</strong> Vemos qu√© tan mal predice nuestro modelo actualmente.
                    </li>
                    <li>
                        <strong>C√°lculo del Gradiente:</strong> Calculamos la derivada (la pendiente) de la funci√≥n de error. Esto nos dice en qu√© direcci√≥n debemos movernos para aumentar el error.
                    </li>
                    <li>
                        <strong>Actualizaci√≥n (El paso):</strong> Nos movemos en la direcci√≥n <em>opuesta</em> al gradiente para reducir el error.
                    </li>
                </ol>

                <CodeBlock
                    title="El Algoritmo en Python (simplificado)"
                    language="python"
                    code={`# Repetir hasta converger:
W = W - learning_rate * gradiente(W)`}
                />
            </Section>

            <Section title="Learning Rate (Tasa de Aprendizaje)" icon={<Compass />}>
                <p className="mb-4">
                    Es el hiperpar√°metro m√°s importante. Decide qu√© tan grandes son los "pasos" que damos bajando la monta√±a.
                </p>

                <div className="grid grid-cols-1 md:grid-cols-3 gap-4">
                    <div className="p-4 bg-red-50 dark:bg-red-900/20 rounded-lg border border-red-200">
                        <h4 className="font-bold text-red-600 mb-2">Muy Alto</h4>
                        <p className="text-sm">Damos saltos gigantes. Podr√≠amos saltarnos el valle completamente e incluso subir al otro lado (divergencia).</p>
                    </div>
                    <div className="p-4 bg-yellow-50 dark:bg-yellow-900/20 rounded-lg border border-yellow-200">
                        <h4 className="font-bold text-yellow-600 mb-2">Muy Bajo</h4>
                        <p className="text-sm">Pasos de hormiga. Llegaremos al valle, pero nos tomar√° una eternidad (lento).</p>
                    </div>
                    <div className="p-4 bg-green-50 dark:bg-green-900/20 rounded-lg border border-green-200">
                        <h4 className="font-bold text-green-600 mb-2">Justo</h4>
                        <p className="text-sm">Pasos adecuados. Convergencia r√°pida y estable hacia el m√≠nimo global.</p>
                    </div>
                </div>
            </Section>

            <KeyConcept title="M√≠nimos Locales vs Globales">
                Uno de los peligros es quedarse atascado en un "peque√±o valle" (m√≠nimo local) pensando que es el punto m√°s bajo de todos (m√≠nimo global).
                <br /><br />
                Variantes modernas como <strong>SGD (Stochastic Gradient Descent)</strong> o optimizadores como <strong>Adam</strong> ayudan a evitar este problema a√±adiendo "momentum" o aleatoriedad.
            </KeyConcept>

            <Example title="Analog√≠a Visual" color="green">
                <p>
                    Piensa en una bola rodando dentro de un taz√≥n.
                </p>
                <ul className="list-disc list-inside mt-2 ml-2">
                    <li>El taz√≥n es la funci√≥n de Costo (Loss Function).</li>
                    <li>La posici√≥n de la bola son los Pesos (Weights) del modelo.</li>
                    <li>La gravedad es el Gradiente.</li>
                    <li>El fondo del taz√≥n es el modelo perfecto.</li>
                </ul>
            </Example>
        </ArticleLayout>
    );
};
