# Gradient Descent

## Introducci√≥n

**Gradient Descent** (Descenso de Gradiente) es el algoritmo de optimizaci√≥n m√°s fundamental en machine learning. Es el motor que permite a las redes neuronales y muchos otros modelos "aprender" ajustando sus par√°metros para minimizar el error.

## Concepto B√°sico

Imagina que est√°s en una monta√±a con los ojos vendados y quieres llegar al valle (punto m√°s bajo). Tu estrategia:
1. Sientes la pendiente bajo tus pies
2. Das un paso en la direcci√≥n de mayor descenso
3. Repites hasta llegar al fondo

Esto es exactamente lo que hace gradient descent con funciones matem√°ticas.

## La Funci√≥n de Costo

Queremos minimizar una **funci√≥n de costo** (loss function) que mide qu√© tan mal est√° nuestro modelo.

### Ejemplo: Regresi√≥n Lineal
```
J(Œ∏) = (1/2m) Œ£(hŒ∏(xi) - yi)¬≤
```

Donde:
- **J(Œ∏)**: Funci√≥n de costo (Mean Squared Error)
- **Œ∏**: Par√°metros del modelo
- **hŒ∏(x)**: Predicci√≥n del modelo
- **y**: Valor real
- **m**: N√∫mero de ejemplos

## El Gradiente

El **gradiente** es un vector que apunta en la direcci√≥n de mayor aumento de la funci√≥n.

```
‚àáJ(Œ∏) = [‚àÇJ/‚àÇŒ∏‚ÇÄ, ‚àÇJ/‚àÇŒ∏‚ÇÅ, ..., ‚àÇJ/‚àÇŒ∏‚Çô]
```

**Intuici√≥n**: Si el gradiente apunta "arriba", vamos en direcci√≥n opuesta para "bajar".

## Algoritmo de Gradient Descent

### F√≥rmula de Actualizaci√≥n

```
Œ∏ := Œ∏ - Œ±‚àáJ(Œ∏)
```

Donde:
- **Œ∏**: Par√°metros actuales
- **Œ±**: Learning rate (tasa de aprendizaje)
- **‚àáJ(Œ∏)**: Gradiente de la funci√≥n de costo

### Pasos del Algoritmo

1. **Inicializar** Œ∏ aleatoriamente
2. **Calcular** el gradiente ‚àáJ(Œ∏)
3. **Actualizar** Œ∏ = Œ∏ - Œ±‚àáJ(Œ∏)
4. **Repetir** pasos 2-3 hasta convergencia

## Learning Rate (Œ±)

El **learning rate** controla el tama√±o del paso en cada iteraci√≥n.

### Learning Rate Muy Peque√±o
```
Œ± = 0.001
```
- ‚úì Convergencia garantizada (si es convexo)
- ‚úó Muy lento
- ‚úó Puede quedar atascado

### Learning Rate Muy Grande
```
Œ± = 1.0
```
- ‚úó Puede divergir
- ‚úó Oscila sin converger
- ‚úó Salta sobre el m√≠nimo

### Learning Rate √ìptimo
```
Œ± = 0.01 - 0.1 (depende del problema)
```
- ‚úì Convergencia r√°pida
- ‚úì Estable
- ‚úì Encuentra el m√≠nimo

## Visualizaci√≥n

### Superficie de Costo 3D
```
        J(Œ∏)
         ‚Üë
         |     ‚ï±‚ï≤
         |    ‚ï±  ‚ï≤
         |   ‚ï±    ‚ï≤
         |  ‚ï±  ‚Ä¢   ‚ï≤  ‚Üê Punto inicial
         | ‚ï±   ‚Üì    ‚ï≤
         |‚ï±    ‚òÖ     ‚ï≤ ‚Üê M√≠nimo global
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí Œ∏
```

El algoritmo sigue la pendiente hacia abajo hasta el m√≠nimo (‚òÖ).

## Variantes de Gradient Descent

### 1. Batch Gradient Descent

Usa **todos** los datos en cada iteraci√≥n.

```
Œ∏ := Œ∏ - Œ±(1/m)Œ£‚àáJ(Œ∏; xi, yi)
```

**Ventajas**:
- ‚úì Convergencia suave
- ‚úì Garantiza encontrar m√≠nimo (si es convexo)

**Desventajas**:
- ‚úó Muy lento con datasets grandes
- ‚úó No puede manejar datos que no caben en memoria

### 2. Stochastic Gradient Descent (SGD)

Usa **un solo** ejemplo en cada iteraci√≥n.

```
Œ∏ := Œ∏ - Œ±‚àáJ(Œ∏; xi, yi)
```

**Ventajas**:
- ‚úì Muy r√°pido
- ‚úì Puede escapar de m√≠nimos locales
- ‚úì Funciona con datos en streaming

**Desventajas**:
- ‚úó Ruidoso, oscila mucho
- ‚úó No converge exactamente al m√≠nimo

### 3. Mini-Batch Gradient Descent

Usa un **peque√±o lote** de ejemplos (t√≠picamente 32-256).

```
Œ∏ := Œ∏ - Œ±(1/b)Œ£‚àáJ(Œ∏; xi, yi)  # b = batch size
```

**Ventajas**:
- ‚úì Balance entre velocidad y estabilidad
- ‚úì Aprovecha paralelizaci√≥n (GPUs)
- ‚úì M√°s usado en pr√°ctica

**Desventajas**:
- ‚ö†Ô∏è Requiere ajustar batch size

## Ejemplo Num√©rico

**Problema**: Minimizar J(Œ∏) = Œ∏¬≤

### Iteraciones con Œ± = 0.1

```
Inicio: Œ∏ = 10

Iteraci√≥n 1:
‚àáJ = 2Œ∏ = 20
Œ∏ = 10 - 0.1(20) = 8

Iteraci√≥n 2:
‚àáJ = 2Œ∏ = 16
Œ∏ = 8 - 0.1(16) = 6.4

Iteraci√≥n 3:
‚àáJ = 2Œ∏ = 12.8
Œ∏ = 6.4 - 0.1(12.8) = 5.12

...

Convergencia: Œ∏ ‚Üí 0 (el m√≠nimo)
```

## Criterios de Parada

¬øCu√°ndo detener el algoritmo?

### 1. N√∫mero M√°ximo de Iteraciones
```
if iteration >= max_iterations:
    stop
```

### 2. Cambio Peque√±o en Par√°metros
```
if |Œ∏_new - Œ∏_old| < Œµ:
    stop
```

### 3. Cambio Peque√±o en Costo
```
if |J(Œ∏_new) - J(Œ∏_old)| < Œµ:
    stop
```

### 4. Gradiente Peque√±o
```
if ||‚àáJ(Œ∏)|| < Œµ:
    stop
```

## Problemas Comunes

### 1. M√≠nimos Locales

En funciones no convexas:
```
J(Œ∏)
  ‚Üë
  |  ‚ï±‚ï≤    ‚ï±‚ï≤
  | ‚ï±  ‚ï≤  ‚ï±  ‚ï≤
  |‚ï± ‚òÖ‚ÇÅ ‚ï≤‚ï± ‚òÖ‚ÇÇ ‚ï≤
  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí Œ∏
```

- ‚òÖ‚ÇÅ: M√≠nimo local (malo)
- ‚òÖ‚ÇÇ: M√≠nimo global (bueno)

**Soluciones**:
- M√∫ltiples inicializaciones aleatorias
- Momentum
- Adaptive learning rates

### 2. Saddle Points (Puntos de Silla)

Puntos donde el gradiente es cero pero no son m√≠nimos:
```
      ‚ï±‚ï≤
     ‚ï±  ‚ï≤
‚îÄ‚îÄ‚îÄ‚îÄ‚ï± ‚òÖ  ‚ï≤‚îÄ‚îÄ‚îÄ‚îÄ
   ‚ï±      ‚ï≤
```

**Soluci√≥n**: Momentum ayuda a escapar

### 3. Plateaus (Mesetas)

Regiones planas donde el gradiente es muy peque√±o:
```
J(Œ∏)
  ‚Üë
  |     ________
  |    ‚ï±        ‚ï≤
  |   ‚ï±          ‚ï≤
  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí Œ∏
```

**Soluci√≥n**: Adaptive learning rates

## Optimizadores Avanzados

### Momentum

Acumula velocidad en direcciones consistentes:

```
v := Œ≤v + Œ±‚àáJ(Œ∏)
Œ∏ := Œ∏ - v
```

- **Œ≤**: T√≠picamente 0.9
- Acelera en direcciones consistentes
- Amortigua oscilaciones

### RMSprop

Adapta el learning rate por par√°metro:

```
s := Œ≤s + (1-Œ≤)(‚àáJ)¬≤
Œ∏ := Œ∏ - Œ±‚àáJ/‚àö(s + Œµ)
```

- Divide por ra√≠z de promedio de gradientes al cuadrado
- Par√°metros con gradientes grandes ‚Üí pasos peque√±os

### Adam (Adaptive Moment Estimation)

Combina Momentum y RMSprop:

```
m := Œ≤‚ÇÅm + (1-Œ≤‚ÇÅ)‚àáJ     # Momento
v := Œ≤‚ÇÇv + (1-Œ≤‚ÇÇ)(‚àáJ)¬≤  # RMSprop
Œ∏ := Œ∏ - Œ±¬∑m/‚àö(v + Œµ)
```

**Par√°metros t√≠picos**:
- Œ≤‚ÇÅ = 0.9
- Œ≤‚ÇÇ = 0.999
- Œ± = 0.001

**Ventajas**:
- ‚úì Funciona bien en la mayor√≠a de problemas
- ‚úì Requiere poco tuning
- ‚úì M√°s usado en deep learning

## Learning Rate Scheduling

Ajustar Œ± durante el entrenamiento:

### Step Decay
```
Œ± = Œ±‚ÇÄ √ó 0.5^(epoch/10)
```

### Exponential Decay
```
Œ± = Œ±‚ÇÄ √ó e^(-kt)
```

### Cosine Annealing
```
Œ± = Œ±_min + 0.5(Œ±_max - Œ±_min)(1 + cos(œÄt/T))
```

## Aplicaciones

### En Redes Neuronales
- Backpropagation usa gradient descent
- Actualiza pesos en cada capa
- Minimiza cross-entropy o MSE

### En Regresi√≥n Lineal
- Encuentra Œ≤‚ÇÄ y Œ≤‚ÇÅ √≥ptimos
- Minimiza suma de errores cuadrados

### En Logistic Regression
- Optimiza par√°metros para clasificaci√≥n
- Minimiza log-loss

### En Deep Learning
- Entrenar CNNs, RNNs, Transformers
- Millones de par√°metros
- Requiere GPUs

## Consejos Pr√°cticos

### 1. Normalizar Features
```
x_norm = (x - Œº) / œÉ
```
- Hace que la optimizaci√≥n sea m√°s r√°pida
- Evita que unas features dominen

### 2. Inicializaci√≥n
- No inicializar todos a cero
- Xavier/He initialization para redes neuronales

### 3. Monitorear P√©rdida
- Graficar J(Œ∏) vs iteraciones
- Debe disminuir consistentemente

### 4. Batch Size
- M√°s grande ‚Üí m√°s estable, m√°s lento
- M√°s peque√±o ‚Üí m√°s ruidoso, m√°s r√°pido
- T√≠pico: 32, 64, 128, 256

## Visualizaci√≥n de Convergencia

```
Loss
  ‚Üë
  |‚ï≤
  | ‚ï≤___
  |     ‚ï≤___
  |         ‚ï≤___
  |             ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí Iterations
```

**Buena convergencia**: Disminuci√≥n suave hacia un valor estable.

## Conclusi√≥n

Gradient Descent es:
- üéØ El algoritmo de optimizaci√≥n fundamental en ML
- üöÄ La base de c√≥mo las redes neuronales aprenden
- ‚öôÔ∏è Simple en concepto, poderoso en pr√°ctica

**Claves del √©xito**:
- Elegir buen learning rate
- Usar variante apropiada (SGD, Adam, etc.)
- Normalizar datos
- Monitorear convergencia

## Juegos Relacionados

üéÆ [Gradient Descent Visualizer](/game/gradient-descent) - Visualiza el descenso en superficies 3D

---

*Siguiente: [Redes Neuronales](/wiki/redes-neuronales)*
