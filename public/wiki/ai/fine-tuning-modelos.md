# Fine-Tuning de Modelos de IA

## Introducci√≥n

El **fine-tuning** (ajuste fino) es el proceso de adaptar un modelo de IA pre-entrenado a una tarea espec√≠fica. En lugar de entrenar desde cero, aprovechamos el conocimiento ya aprendido por el modelo en grandes conjuntos de datos y lo especializamos para nuestra aplicaci√≥n. Esta t√©cnica es fundamental en el desarrollo moderno de IA, especialmente con modelos grandes donde el entrenamiento completo ser√≠a prohibitivamente costoso.

## Conceptos Fundamentales

### ¬øQu√© es Fine-Tuning?

**Definici√≥n:** Continuar el entrenamiento de un modelo pre-entrenado en un dataset m√°s peque√±o y espec√≠fico.

**Analog√≠a:** Es como un m√©dico general (modelo pre-entrenado) que se especializa en cardiolog√≠a (fine-tuning).

### Transfer Learning

Fine-tuning es una forma de **transfer learning**:
- Modelo aprende de tarea general (pre-entrenamiento)
- Transfiere conocimiento a tarea espec√≠fica (fine-tuning)

### Pre-entrenamiento vs Fine-Tuning

**Pre-entrenamiento:**
- Dataset masivo (millones a billones de ejemplos)
- Tarea general (e.g., predecir siguiente palabra)
- Computacionalmente costoso (semanas, GPUs/TPUs)

**Fine-Tuning:**
- Dataset peque√±o (cientos a miles de ejemplos)
- Tarea espec√≠fica (e.g., clasificar reviews de productos)
- Relativamente r√°pido (horas, GPU est√°ndar)

## ¬øPor Qu√© Fine-Tuning?

### Ventajas

‚úÖ **Menos datos requeridos:** Miles vs millones
‚úÖ **M√°s r√°pido:** Horas vs semanas
‚úÖ **M√°s barato:** GPUs est√°ndar vs clusters masivos
‚úÖ **Mejor desempe√±o:** Aprovecha conocimiento previo
‚úÖ **Menor overfitting:** Modelo ya tiene regularizaci√≥n natural

### Cu√°ndo Usar

- Tienes tarea espec√≠fica
- Dataset limitado (< 100k ejemplos)
- Recursos computacionales limitados
- Necesitas resultados r√°pidos
- Existe modelo pre-entrenado relevante

## Tipos de Fine-Tuning

### 1. Feature Extraction

Congelar modelo pre-entrenado, entrenar solo capas finales.

**Proceso:**
```python
# Congelar capas base
for param in base_model.parameters():
    param.requires_grad = False

# Entrenar solo cabeza de clasificaci√≥n
classifier = nn.Linear(base_features, num_classes)
```

**Cu√°ndo usar:**
- Dataset muy peque√±o
- Tarea similar a pre-entrenamiento
- Recursos muy limitados

### 2. Full Fine-Tuning

Entrenar todas las capas del modelo.

**Proceso:**
```python
# Todas las capas entrenables
model = PretrainedModel()
optimizer = Adam(model.parameters(), lr=1e-5)  # Learning rate bajo
```

**Cu√°ndo usar:**
- Dataset mediano (10k+ ejemplos)
- Tarea diferente a pre-entrenamiento
- Recursos suficientes

### 3. Gradual Unfreezing

Descongelar capas progresivamente.

**Proceso:**
1. Entrenar solo cabeza
2. Descongelar √∫ltimas capas, entrenar
3. Descongelar m√°s capas, entrenar
4. Repetir hasta el inicio

**Ventaja:** Previene catastrophic forgetting

### 4. Discriminative Fine-Tuning

Learning rates diferentes por capa.

**Idea:** Capas tempranas cambian poco, capas finales m√°s.

```python
optimizer = Adam([
    {'params': model.layer1.parameters(), 'lr': 1e-6},
    {'params': model.layer2.parameters(), 'lr': 1e-5},
    {'params': model.layer3.parameters(), 'lr': 1e-4},
])
```

## Fine-Tuning en Diferentes Dominios

### Computer Vision (CNN)

**Modelos pre-entrenados:**
- ResNet, VGG (ImageNet)
- EfficientNet
- Vision Transformer (ViT)

**Tareas:**
- Clasificaci√≥n de im√°genes m√©dicas
- Detecci√≥n de objetos personalizados
- Segmentaci√≥n espec√≠fica

**Ejemplo:**
```python
from torchvision.models import resnet50

# Cargar modelo pre-entrenado
model = resnet50(pretrained=True)

# Reemplazar √∫ltima capa
model.fc = nn.Linear(2048, num_classes)

# Fine-tune
optimizer = Adam(model.parameters(), lr=1e-4)
```

### NLP (Transformers)

**Modelos pre-entrenados:**
- BERT, RoBERTa
- GPT-2, GPT-3
- T5, LLaMA

**Tareas:**
- Clasificaci√≥n de texto espec√≠fica del dominio
- NER personalizado
- Question answering sobre documentos espec√≠ficos

**Ejemplo con Hugging Face:**
```python
from transformers import BertForSequenceClassification, Trainer

model = BertForSequenceClassification.from_pretrained(
    'bert-base-uncased',
    num_labels=num_classes
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=eval_dataset
)

trainer.train()
```

### Speech Recognition

**Modelos:**
- Wav2Vec 2.0
- Whisper

**Tareas:**
- Transcripci√≥n en idiomas espec√≠ficos
- Reconocimiento de comandos personalizados

## Mejores Pr√°cticas

### 1. Learning Rate

**Regla general:** 10-100x m√°s peque√±o que pre-entrenamiento.

**T√≠pico:**
- Pre-entrenamiento: 1e-3
- Fine-tuning: 1e-5 a 1e-4

**T√©cnica:**
- Learning rate warmup
- Learning rate decay

### 2. Epochs

**Pocos epochs** para evitar overfitting:
- 3-5 epochs t√≠picamente suficientes
- Monitorear validation loss

### 3. Regularizaci√≥n

**T√©cnicas:**
- **Dropout:** 0.1-0.3
- **Weight decay:** 0.01
- **Early stopping**
- **Data augmentation**

### 4. Batch Size

Balance entre memoria y estabilidad:
- Menor que pre-entrenamiento
- 8-32 t√≠picamente

### 5. Evaluaci√≥n Frecuente

Evaluar cada epoch o m√°s frecuentemente.

**Guardar:**
- Mejor modelo seg√∫n validation
- Checkpoints regulares

## Parameter-Efficient Fine-Tuning (PEFT)

M√©todos para fine-tunear con menos par√°metros modificados.

### LoRA (Low-Rank Adaptation)

A√±adir matrices de rango bajo en lugar de fine-tunear pesos completos.

**Ventajas:**
- 10,000x menos par√°metros entrenables
- Misma o mejor performance
- M√∫ltiples adaptadores para diferentes tareas

### Adapter Layers

Insertar capas peque√±as adicionales.

**Ventaja:** Congelar modelo base, entrenar solo adapters.

### Prefix Tuning

A√±adir vectores aprendibles al inicio de secuencias.

**Uso:** LLMs como GPT

### Prompt Tuning

Optimizar "soft prompts" (embeddings continuos).

**Diferencia con Prefix:** Solo en input layer.

## Fine-Tuning de LLMs

### Casos de Uso

**Adaptaci√≥n de dominio:**
- Terminolog√≠a m√©dica/legal espec√≠fica
- Estilo de escritura empresarial
- Conocimiento especializado

**Seguimiento de instrucciones:**
- Chatbots personalizados
- Asistentes espec√≠ficos

**Alineaci√≥n:**
- RLHF (Reinforcement Learning from Human Feedback)
- Constitutional AI

### T√©cnicas Especiales

**Instruction Tuning:**
Entrenar en pares (instruction, output).

**RLHF:**
1. Fine-tune con supervised learning
2. Entrenar modelo de recompensa
3. Optimizar con PPO

**Few-Shot In-Context Learning:**
Alternativa a fine-tuning para LLMs grandes.

## Desaf√≠os

### Catastrophic Forgetting

Modelo olvida conocimiento del pre-entrenamiento.

**Soluciones:**
- Learning rate bajo
- Regularizaci√≥n
- Gradual unfreezing
- Mixup training (mezclar datos originales)

### Overfitting

Especialmente con datos limitados.

**Soluciones:**
- Data augmentation
- Dropout
- Early stopping
- M√°s datos (data synthesis, web scraping)

### Domain Gap

Gran diferencia entre datos de pre-entrenamiento y fine-tuning.

**Soluci√≥n:**
- Intermediate fine-tuning (adaptar progresivamente)
- Domain-adaptive pre-training

## Evaluaci√≥n

### M√©tricas por Tarea

**Clasificaci√≥n:**
- Accuracy, F1, Precision, Recall

**Generaci√≥n:**
- BLEU, ROUGE, Human evaluation

**QA:**
- Exact Match, F1

### Comparaci√≥n

Comparar con:
- **Baseline:** Modelo desde cero
- **Pre-trained:** Sin fine-tuning
- **State-of-the-art:** Mejores modelos publicados

## Herramientas y Frameworks

### Hugging Face Transformers

```python
from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer

model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased')

training_args = TrainingArguments(
    output_dir='./results',
    num_train_epochs=3,
    per_device_train_batch_size=16,
    learning_rate=2e-5,
    weight_decay=0.01,
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=eval_dataset
)

trainer.train()
```

### PyTorch

```python
import torch.nn as nn
from torchvision.models import resnet50

model = resnet50(pretrained=True)
model.fc = nn.Linear(2048, num_classes)

# Congelar capas excepto √∫ltima
for name, param in model.named_parameters():
    if 'fc' not in name:
        param.requires_grad = False

optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()))
```

### TensorFlow/Keras

```python
from tensorflow.keras.applications import ResNet50
from tensorflow.keras import layers, Model

base_model = ResNet50(weights='imagenet', include_top=False)
base_model.trainable = False  # Congelar

x = layers.GlobalAveragePooling2D()(base_model.output)
outputs = layers.Dense(num_classes, activation='softmax')(x)

model = Model(base_model.input, outputs)
model.compile(optimizer='adam', loss='categorical_crossentropy')
```

## Casos de Uso Reales

### Medicina

**Radiolog√≠a:**
- Fine-tune ImageNet models en rayos X
- Detectar enfermedades espec√≠ficas

### Legal

**An√°lisis de documentos:**
- Fine-tune BERT en contratos legales
- Extracci√≥n de cl√°usulas

### E-commerce

**Recomendaciones:**
- Fine-tune en historial de compras
- Descripciones de productos

### Customer Service

**Chatbots:**
- Fine-tune GPT en conversaciones hist√≥ricas
- Respuestas consistentes con marca

## Futuro del Fine-Tuning

### Tendencias

**Modelos m√°s grandes:**
- GPT-4, PaLM, LLaMA cada vez m√°s grandes
- Fine-tuning m√°s costoso ‚Üí PEFT m√°s importante

**In-Context Learning:**
- Pocos ejemplos en prompt vs fine-tuning
- Competencia para tareas simples

**Automatic Fine-Tuning:**
- AutoML para fine-tuning
- B√∫squeda autom√°tica de hiperpar√°metros

**Multimodal:**
- Fine-tuning de modelos visi√≥n + lenguaje
- CLIP, Flamingo, GPT-4V

## Juegos Relacionados

üéÆ [Clasificador Visual](/game/visual-classifier) - Experimenta con transfer learning

üéÆ [Prompt Engineering](/game/prompt-engineering) - Compara con in-context learning

## Recursos Adicionales

- Hugging Face Fine-Tuning Tutorial
- Fast.ai: Transfer Learning Course
- Stanford CS25: Transformers United
- LoRA: Low-Rank Adaptation Paper
- PEFT Library (Hugging Face)

---

*Anterior: [Procesamiento de Lenguaje Natural](/wiki/procesamiento-lenguaje-natural) | Siguiente: [Agentes Aut√≥nomos](/wiki/agentes-autonomos)*
