# Pruebas de Hip√≥tesis

## Introducci√≥n

Las **pruebas de hip√≥tesis** son procedimientos estad√≠sticos que permiten tomar decisiones sobre poblaciones bas√°ndose en informaci√≥n de muestras. Son fundamentales en la investigaci√≥n cient√≠fica, control de calidad, medicina, y ciencia de datos para determinar si los resultados observados son estad√≠sticamente significativos o simplemente debidos al azar.

## Conceptos Fundamentales

### ¬øQu√© es una Hip√≥tesis?

Una **hip√≥tesis** es una afirmaci√≥n sobre un par√°metro poblacional (media, proporci√≥n, varianza, etc.) que queremos probar con evidencia de una muestra.

### Tipos de Hip√≥tesis

**Hip√≥tesis Nula (H‚ÇÄ):**
- La hip√≥tesis de "no efecto" o "no diferencia"
- Lo que asumimos como verdadero hasta probar lo contrario
- Ejemplo: Œº = 100, p = 0.5, Œº‚ÇÅ = Œº‚ÇÇ

**Hip√≥tesis Alternativa (H‚ÇÅ o H‚Çê):**
- La hip√≥tesis que queremos probar
- Puede ser bilateral o unilateral
- Ejemplo: Œº ‚â† 100, p > 0.5, Œº‚ÇÅ < Œº‚ÇÇ

### Tipos de Pruebas

**Prueba Bilateral (dos colas):**
```
H‚ÇÄ: Œº = Œº‚ÇÄ
H‚ÇÅ: Œº ‚â† Œº‚ÇÄ
```
Detecta diferencias en cualquier direcci√≥n.

**Prueba Unilateral Derecha (cola derecha):**
```
H‚ÇÄ: Œº ‚â§ Œº‚ÇÄ
H‚ÇÅ: Œº > Œº‚ÇÄ
```
Detecta si el par√°metro es mayor.

**Prueba Unilateral Izquierda (cola izquierda):**
```
H‚ÇÄ: Œº ‚â• Œº‚ÇÄ
H‚ÇÅ: Œº < Œº‚ÇÄ
```
Detecta si el par√°metro es menor.

## Proceso de Prueba de Hip√≥tesis

### Paso 1: Formular Hip√≥tesis

Definir claramente H‚ÇÄ y H‚ÇÅ.

### Paso 2: Elegir Nivel de Significancia (Œ±)

**Œ±** es la probabilidad de rechazar H‚ÇÄ cuando es verdadera (Error Tipo I).

Valores comunes:
- Œ± = 0.05 (5%) - Est√°ndar en muchos campos
- Œ± = 0.01 (1%) - M√°s conservador
- Œ± = 0.10 (10%) - Menos estricto

### Paso 3: Calcular Estad√≠stico de Prueba

Depende del tipo de prueba y datos disponibles:
- Test z para proporciones o medias (œÉ conocida)
- Test t para medias (œÉ desconocida)
- Test œá¬≤ para varianzas o tablas de contingencia
- Test F para comparar varianzas

### Paso 4: Calcular Valor p

El **valor p** es la probabilidad de obtener un resultado tan extremo o m√°s que el observado, asumiendo que H‚ÇÄ es verdadera.

**Interpretaci√≥n:**
- p < Œ±: Rechazar H‚ÇÄ (resultado significativo)
- p ‚â• Œ±: No rechazar H‚ÇÄ (resultado no significativo)

### Paso 5: Tomar Decisi√≥n

- **Rechazar H‚ÇÄ**: Hay evidencia suficiente para H‚ÇÅ
- **No rechazar H‚ÇÄ**: No hay evidencia suficiente para H‚ÇÅ

**Nota:** "No rechazar H‚ÇÄ" NO significa que H‚ÇÄ sea verdadera, solo que no hay evidencia suficiente en contra.

## Tipos de Errores

### Error Tipo I (Falso Positivo)

Rechazar H‚ÇÄ cuando es verdadera.
```
P(Error Tipo I) = Œ±
```

**Ejemplo:** Concluir que un medicamento funciona cuando en realidad no tiene efecto.

### Error Tipo II (Falso Negativo)

No rechazar H‚ÇÄ cuando es falsa.
```
P(Error Tipo II) = Œ≤
```

**Ejemplo:** Concluir que un medicamento no funciona cuando s√≠ tiene efecto.

### Potencia de la Prueba

```
Potencia = 1 - Œ≤
```

Probabilidad de rechazar H‚ÇÄ correctamente cuando es falsa.

**Factores que aumentan la potencia:**
- Mayor tama√±o de muestra (n)
- Mayor Œ± (pero aumenta Error Tipo I)
- Mayor tama√±o del efecto
- Menor variabilidad

## Pruebas Comunes

### 1. Test t de Una Muestra

Probar si la media de una poblaci√≥n difiere de un valor espec√≠fico.

**Hip√≥tesis:**
```
H‚ÇÄ: Œº = Œº‚ÇÄ
H‚ÇÅ: Œº ‚â† Œº‚ÇÄ
```

**Estad√≠stico:**
```
t = (xÃÑ - Œº‚ÇÄ) / (s / ‚àön)
```

Con n-1 grados de libertad.

**Ejemplo:** ¬øLa altura promedio de estudiantes es 170 cm?

### 2. Test t de Dos Muestras Independientes

Comparar medias de dos grupos independientes.

**Hip√≥tesis:**
```
H‚ÇÄ: Œº‚ÇÅ = Œº‚ÇÇ
H‚ÇÅ: Œº‚ÇÅ ‚â† Œº‚ÇÇ
```

**Ejemplo:** ¬øHay diferencia en salarios entre hombres y mujeres?

### 3. Test t Pareado

Comparar medias de dos muestras relacionadas.

**Hip√≥tesis:**
```
H‚ÇÄ: Œºd = 0 (diferencia promedio = 0)
H‚ÇÅ: Œºd ‚â† 0
```

**Ejemplo:** ¬øEl tratamiento reduce la presi√≥n arterial? (antes vs despu√©s)

### 4. Test z para Proporciones

Probar hip√≥tesis sobre una proporci√≥n poblacional.

**Estad√≠stico:**
```
z = (pÃÇ - p‚ÇÄ) / ‚àö(p‚ÇÄ(1-p‚ÇÄ)/n)
```

**Ejemplo:** ¬øLa tasa de conversi√≥n es diferente del 10%?

### 5. Test Chi-Cuadrado (œá¬≤)

**Bondad de Ajuste:**
Probar si los datos siguen una distribuci√≥n espec√≠fica.

**Independencia:**
Probar si dos variables categ√≥ricas son independientes.

**Ejemplo:** ¬øLa preferencia de producto es independiente del g√©nero?

### 6. ANOVA (An√°lisis de Varianza)

Comparar medias de tres o m√°s grupos.

**Hip√≥tesis:**
```
H‚ÇÄ: Œº‚ÇÅ = Œº‚ÇÇ = Œº‚ÇÉ = ... = Œºk
H‚ÇÅ: Al menos una media es diferente
```

**Ejemplo:** ¬øHay diferencia en productividad entre tres turnos de trabajo?

## Ejemplos Pr√°cticos

### Ejemplo 1: Test t de Una Muestra

Una empresa afirma que sus empleados trabajan en promedio 40 horas/semana. Una muestra de 25 empleados muestra:
- xÃÑ = 42.5 horas
- s = 5 horas

**Prueba:**
```
H‚ÇÄ: Œº = 40
H‚ÇÅ: Œº ‚â† 40
Œ± = 0.05

t = (42.5 - 40) / (5/‚àö25) = 2.5 / 1 = 2.5
gl = 24

Valor cr√≠tico: t‚ÇÄ.‚ÇÄ‚ÇÇ‚ÇÖ,‚ÇÇ‚ÇÑ ‚âà 2.064
```

Como |2.5| > 2.064, rechazamos H‚ÇÄ.

**Conclusi√≥n:** Hay evidencia de que el promedio no es 40 horas.

### Ejemplo 2: Test de Proporciones

Un sitio web tiene tasa de conversi√≥n hist√≥rica del 5%. Despu√©s de redise√±o, de 500 visitantes, 35 convierten.

```
H‚ÇÄ: p = 0.05
H‚ÇÅ: p ‚â† 0.05
Œ± = 0.05

pÃÇ = 35/500 = 0.07

z = (0.07 - 0.05) / ‚àö(0.05√ó0.95/500)
  = 0.02 / 0.00974
  = 2.05

Valor cr√≠tico: z‚ÇÄ.‚ÇÄ‚ÇÇ‚ÇÖ = 1.96
```

Como 2.05 > 1.96, rechazamos H‚ÇÄ.

**Conclusi√≥n:** El redise√±o mejor√≥ la conversi√≥n significativamente.

### Ejemplo 3: A/B Testing

**Grupo A (control):** 1000 usuarios, 50 conversiones (5%)
**Grupo B (variante):** 1000 usuarios, 65 conversiones (6.5%)

```
H‚ÇÄ: pA = pB
H‚ÇÅ: pA ‚â† pB

Test z para dos proporciones:
z = (pÃÇA - pÃÇB) / ‚àö(pÃÇ(1-pÃÇ)(1/nA + 1/nB))

Donde pÃÇ = (50 + 65)/(1000 + 1000) = 0.0575

z = (0.05 - 0.065) / ‚àö(0.0575√ó0.9425√ó0.002)
  = -0.015 / 0.0104
  = -1.44

|z| < 1.96, no rechazamos H‚ÇÄ
```

**Conclusi√≥n:** No hay evidencia suficiente de diferencia significativa.

## Significancia Estad√≠stica vs Pr√°ctica

**Significancia Estad√≠stica:**
- p < Œ± (rechazamos H‚ÇÄ)
- Indica que el efecto no es por azar

**Significancia Pr√°ctica:**
- ¬øEl efecto es lo suficientemente grande para importar?
- Depende del contexto y costo

**Ejemplo:** Con n=1,000,000, una diferencia de 0.1% puede ser estad√≠sticamente significativa pero pr√°cticamente irrelevante.

## Intervalo de Confianza vs Prueba de Hip√≥tesis

Los **intervalos de confianza** proporcionan informaci√≥n complementaria:

**Intervalo de 95% para Œº:**
```
xÃÑ ¬± t‚ÇÄ.‚ÇÄ‚ÇÇ‚ÇÖ √ó (s/‚àön)
```

Si el intervalo NO contiene Œº‚ÇÄ, rechazamos H‚ÇÄ al nivel 0.05.

**Ventaja del IC:** Muestra rango plausible de valores, no solo s√≠/no.

## M√∫ltiples Comparaciones

Al hacer m√∫ltiples pruebas, la probabilidad de Error Tipo I aumenta:

```
P(al menos un error) = 1 - (1-Œ±)^m
```

Donde m = n√∫mero de pruebas.

**Correcciones:**
- **Bonferroni:** Usar Œ±/m para cada prueba
- **Holm:** Procedimiento secuencial
- **FDR (False Discovery Rate):** Controlar tasa de falsos positivos

## Supuestos y Robustez

### Test t
**Supuestos:**
- Normalidad (o n grande por TLC)
- Independencia de observaciones
- Para dos muestras: Varianzas iguales (o usar Welch)

**Robustez:** Bastante robusto a violaciones leves con n ‚â• 30

### Alternativas No Param√©tricas

Cuando los supuestos no se cumplen:
- **Mann-Whitney U:** Alternativa a test t de dos muestras
- **Wilcoxon:** Alternativa a test t pareado
- **Kruskal-Wallis:** Alternativa a ANOVA
- **Test de Permutaci√≥n:** M√≠nimos supuestos

## Aplicaciones

### Ciencia de Datos
- **A/B Testing:** Comparar variantes de productos
- **Feature Selection:** ¬øLa feature es significativa?
- **Model Comparison:** ¬øUn modelo es mejor que otro?

### Medicina
- **Ensayos Cl√≠nicos:** ¬øEl tratamiento funciona?
- **Epidemiolog√≠a:** ¬øHay asociaci√≥n entre factores?
- **Diagn√≥stico:** ¬øLa prueba es efectiva?

### Negocios
- **Marketing:** Evaluar campa√±as
- **Calidad:** ¬øEl proceso cumple est√°ndares?
- **Finanzas:** Detectar anomal√≠as

### Investigaci√≥n Cient√≠fica
- Probar teor√≠as
- Validar hip√≥tesis
- Replicabilidad de resultados

## C√°lculo con Software

### Python (SciPy)
```python
from scipy import stats

# Test t de una muestra
t_stat, p_value = stats.ttest_1samp(datos, popmean=100)

# Test t de dos muestras
t_stat, p_value = stats.ttest_ind(grupo1, grupo2)

# Test t pareado
t_stat, p_value = stats.ttest_rel(antes, despues)

# Test Chi-cuadrado
chi2, p_value = stats.chi2_contingency(tabla)
```

### R
```R
# Test t de una muestra
t.test(datos, mu=100)

# Test t de dos muestras
t.test(grupo1, grupo2)

# Test pareado
t.test(antes, despues, paired=TRUE)

# ANOVA
aov_result <- aov(valor ~ grupo, data=df)
summary(aov_result)
```

## Cr√≠ticas y Controversias

### Problemas con p-values
- Mal interpretados frecuentemente
- Dependencia del tama√±o de muestra
- P-hacking (buscar significancia)
- Crisis de replicabilidad

### Alternativas Modernas
- **Intervalos de Confianza:** M√°s informativos
- **Tama√±os de Efecto:** Cohen's d, R¬≤
- **Estad√≠stica Bayesiana:** Factor de Bayes
- **Bootstrapping:** M√©todos de remuestreo

## Juegos Relacionados

üéÆ [Detector de Correlaci√≥n](/game/correlation-detector) - Practica identificando relaciones significativas

üéÆ [Regresi√≥n Lineal Builder](/game/linear-regression) - Observa significancia de relaciones lineales

## Recursos Adicionales

- American Statistical Association: Statement on p-values
- Tama√±o de efecto: Cohen's d, Glass's delta
- C√°lculo de tama√±o de muestra: Power analysis
- Bayesian hypothesis testing: Factor de Bayes
- M√∫ltiples comparaciones: FWER vs FDR

---

*Siguiente: [ANOVA](/wiki/anova)*
