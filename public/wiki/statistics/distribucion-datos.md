# Distribuci√≥n de Datos

## Introducci√≥n

La **distribuci√≥n de datos** describe c√≥mo se esparcen los valores en un conjunto de datos. Entender la forma, el centro y la dispersi√≥n de la distribuci√≥n es fundamental para elegir el an√°lisis estad√≠stico apropiado, interpretar resultados correctamente y detectar patrones o anomal√≠as. Una distribuci√≥n puede ser sim√©trica, asim√©trica, unimodal, bimodal, o tener colas pesadas.

## Conceptos Fundamentales

### Componentes de una Distribuci√≥n

1. **Centro**: ¬øD√≥nde se concentran los valores? (media, mediana, moda)
2. **Dispersi√≥n**: ¬øQu√© tan esparcidos est√°n? (rango, desviaci√≥n est√°ndar)
3. **Forma**: ¬øC√≥mo se distribuyen? (sim√©trica, asim√©trica)
4. **Valores at√≠picos**: ¬øHay outliers?

### Tipos de Distribuciones por Forma

#### Distribuci√≥n Sim√©trica
Los datos se distribuyen equitativamente alrededor del centro.
- Media ‚âà Mediana ‚âà Moda
- Ejemplos: Distribuci√≥n normal, distribuci√≥n uniforme

#### Distribuci√≥n Asim√©trica (Sesgada)

**Asimetr√≠a Positiva (derecha):**
- Cola larga hacia la derecha
- Media > Mediana > Moda
- Ejemplos: Ingresos, tiempos de respuesta

**Asimetr√≠a Negativa (izquierda):**
- Cola larga hacia la izquierda
- Moda > Mediana > Media
- Ejemplos: Edad de jubilaci√≥n, calificaciones en ex√°menes f√°ciles

## Distribuciones Comunes

### 1. Distribuci√≥n Normal (Gaussiana)

La m√°s importante en estad√≠stica.

**Caracter√≠sticas:**
- Forma de campana sim√©trica
- Definida por media (Œº) y desviaci√≥n est√°ndar (œÉ)
- 68% de datos dentro de Œº ¬± 1œÉ
- 95% de datos dentro de Œº ¬± 2œÉ
- 99.7% de datos dentro de Œº ¬± 3œÉ

**Ejemplos:**
- Alturas de personas
- Errores de medici√≥n
- Puntajes de CI
- Muchos fen√≥menos naturales

**F√≥rmula:**
```
f(x) = (1 / (œÉ‚àö(2œÄ))) √ó e^(-(x-Œº)¬≤/(2œÉ¬≤))
```

### 2. Distribuci√≥n Uniforme

Todos los valores tienen la misma probabilidad.

**Caracter√≠sticas:**
- Forma rectangular
- Definida por m√≠nimo (a) y m√°ximo (b)
- Media = (a + b) / 2
- Varianza = (b - a)¬≤ / 12

**Ejemplos:**
- N√∫meros aleatorios generados por computadora
- Lanzamiento de dado justo
- Hora de llegada aleatoria en un intervalo

### 3. Distribuci√≥n Exponencial

Modela tiempo entre eventos en un proceso de Poisson.

**Caracter√≠sticas:**
- Asim√©trica positiva pronunciada
- Definida por tasa Œª
- Media = 1/Œª
- Sin memoria: P(X > s+t | X > s) = P(X > t)

**Ejemplos:**
- Tiempo entre llegadas de clientes
- Vida √∫til de componentes electr√≥nicos
- Tiempo entre llamadas telef√≥nicas

### 4. Distribuci√≥n Binomial

N√∫mero de √©xitos en n ensayos independientes.

**Caracter√≠sticas:**
- Discreta
- Par√°metros: n (ensayos) y p (probabilidad de √©xito)
- Media = np
- Varianza = np(1-p)

**Ejemplos:**
- N√∫mero de caras en 10 lanzamientos de moneda
- Productos defectuosos en un lote
- Conversiones en marketing digital

### 5. Distribuci√≥n de Poisson

N√∫mero de eventos en un intervalo fijo.

**Caracter√≠sticas:**
- Discreta
- Par√°metro: Œª (tasa promedio)
- Media = Varianza = Œª
- √ötil para eventos raros

**Ejemplos:**
- Llamadas recibidas por hora
- Accidentes por d√≠a
- Visitas a un sitio web por minuto

### 6. Distribuci√≥n t de Student

Similar a normal pero con colas m√°s pesadas.

**Caracter√≠sticas:**
- Parameterizada por grados de libertad (df)
- Converge a normal cuando df ‚Üí ‚àû
- Usada cuando œÉ es desconocida y n es peque√±o

**Aplicaciones:**
- Intervalos de confianza con muestras peque√±as
- Pruebas t
- Regresi√≥n lineal

### 7. Distribuci√≥n Chi-Cuadrado (œá¬≤)

Suma de cuadrados de variables normales est√°ndar.

**Caracter√≠sticas:**
- Asim√©trica positiva
- Par√°metro: grados de libertad
- Media = df
- Varianza = 2√ódf

**Aplicaciones:**
- Pruebas de bondad de ajuste
- Pruebas de independencia
- Intervalos de confianza para varianza

## Medidas de Forma

### Asimetr√≠a (Skewness)

Cuantifica la direcci√≥n y grado de asimetr√≠a:

```
Skewness = E[(X - Œº)¬≥] / œÉ¬≥
```

**Interpretaci√≥n:**
- Skew = 0: Sim√©trica
- Skew > 0: Asim√©trica positiva (cola derecha)
- Skew < 0: Asim√©trica negativa (cola izquierda)
- |Skew| > 1: Asimetr√≠a fuerte

### Curtosis (Kurtosis)

Mide el peso de las colas:

```
Kurtosis = E[(X - Œº)‚Å¥] / œÉ‚Å¥
```

**Interpretaci√≥n:**
- Kurtosis = 3: Normal (mesoc√∫rtica)
- Kurtosis > 3: Colas pesadas (leptoc√∫rtica)
- Kurtosis < 3: Colas ligeras (platic√∫rtica)

A menudo se usa el **exceso de curtosis** = Kurtosis - 3

## Visualizaci√≥n de Distribuciones

### 1. Histograma
Gr√°fico de barras que muestra frecuencias por intervalos.

**Ventajas:** Muestra la forma completa de la distribuci√≥n
**Desventajas:** Depende del n√∫mero y ancho de bins

### 2. Box Plot (Diagrama de Caja)
Muestra cuartiles, mediana y outliers.

**Componentes:**
- Caja: Q1 a Q3 (IQR)
- L√≠nea central: Mediana
- Bigotes: Hasta 1.5√óIQR desde Q1 y Q3
- Puntos: Outliers

### 3. Gr√°fico de Densidad (KDE)
Versi√≥n suavizada del histograma.

**Ventajas:** Muestra forma continua sin depender de bins
**Desventajas:** Puede suavizar demasiado detalles importantes

### 4. Q-Q Plot (Quantile-Quantile)
Compara cuantiles de dos distribuciones.

**Uso:** Verificar si los datos siguen una distribuci√≥n espec√≠fica (e.g., normal)
**Interpretaci√≥n:** Puntos en l√≠nea recta = buen ajuste

### 5. Violin Plot
Combina box plot con KDE.

**Ventajas:** Muestra tanto la forma como los cuartiles

## Pruebas de Normalidad

### Test de Shapiro-Wilk
- M√°s potente para muestras peque√±as (n < 50)
- H‚ÇÄ: Los datos provienen de una distribuci√≥n normal

### Test de Kolmogorov-Smirnov
- Para muestras m√°s grandes
- Compara distribuci√≥n emp√≠rica con te√≥rica

### Test de Anderson-Darling
- Similar a K-S pero m√°s sensible en las colas

**Nota:** Con muestras muy grandes, cualquier desviaci√≥n peque√±a ser√° significativa. Es mejor usar visualizaci√≥n + tests.

## Transformaciones de Datos

### ¬øPor Qu√© Transformar?

1. **Normalizar** datos asim√©tricos
2. **Estabilizar** varianza
3. **Linearizar** relaciones
4. **Cumplir** supuestos de modelos

### Transformaciones Comunes

**Transformaci√≥n Logar√≠tmica (log):**
- Para asimetr√≠a positiva fuerte
- Ejemplo: log(ingresos), log(poblaci√≥n)

**Transformaci√≥n Ra√≠z Cuadrada (‚àö):**
- Para asimetr√≠a positiva moderada
- √ötil para datos de conteo

**Transformaci√≥n Rec√≠proca (1/x):**
- Para asimetr√≠a positiva muy fuerte
- Ejemplo: 1/tiempo

**Transformaci√≥n Box-Cox:**
- Familia de transformaciones potencia
- Encuentra la transformaci√≥n √≥ptima

**Estandarizaci√≥n (z-score):**
```
z = (x - Œº) / œÉ
```
- Convierte a media 0, desviaci√≥n est√°ndar 1

## Aplicaciones

### Ciencia de Datos
- **An√°lisis Exploratorio**: Entender los datos antes de modelar
- **Feature Engineering**: Transformar caracter√≠sticas para mejorar modelos
- **Detecci√≥n de Anomal√≠as**: Identificar outliers seg√∫n la distribuci√≥n

### Machine Learning
- **Selecci√≥n de Modelo**: Algunos modelos asumen normalidad
- **Preprocessing**: Normalizar features con diferentes distribuciones
- **Evaluaci√≥n**: Distribuci√≥n de errores residuales

### Estad√≠stica Inferencial
- **Elecci√≥n de Test**: Param√©trico vs no param√©trico
- **Validaci√≥n de Supuestos**: ANOVA, regresi√≥n asumen normalidad
- **Intervalos de Confianza**: Basados en distribuci√≥n t o z

### Control de Calidad
- **Gr√°ficos de Control**: Detectar cambios en la distribuci√≥n
- **Capacidad de Proceso**: Evaluar si el proceso cumple especificaciones
- **Six Sigma**: Reducir variabilidad

### Finanzas
- **Modelado de Riesgo**: Distribuciones de retornos
- **Value at Risk**: Basado en cuantiles de la distribuci√≥n
- **Opciones**: Black-Scholes asume distribuci√≥n log-normal

## Mezcla de Distribuciones

Muchos datos reales son **mezclas** de m√∫ltiples distribuciones:

**Ejemplo:** Alturas de adultos = Mezcla de distribuciones de hombres y mujeres

**Identificaci√≥n:**
- Bimodalidad o multimodalidad
- Desviaciones de normalidad
- An√°lisis de subgrupos

## C√°lculo con Software

### Python (SciPy)
```python
from scipy import stats
import numpy as np

datos = np.random.normal(100, 15, 1000)

# Test de normalidad
stat, p = stats.shapiro(datos)

# Asimetr√≠a y curtosis
skew = stats.skew(datos)
kurt = stats.kurtosis(datos)

# Ajustar distribuci√≥n
params = stats.norm.fit(datos)
```

### R
```R
datos <- rnorm(1000, mean=100, sd=15)

# Test de normalidad
shapiro.test(datos)

# Asimetr√≠a y curtosis
library(moments)
skewness(datos)
kurtosis(datos)

# Visualizaci√≥n
hist(datos)
qqnorm(datos); qqline(datos)
```

## Juegos Relacionados

üéÆ [Constructor de Distribuciones](/game/distribution-builder) - Explora diferentes distribuciones interactivamente

üéÆ [Adivina la Medida](/game/guess-measure) - Identifica caracter√≠sticas de distribuciones

üéÆ [Detector de Correlaci√≥n](/game/correlation-detector) - Observa distribuciones bivariadas

## Recursos Adicionales

- Teorema del L√≠mite Central: Por qu√© la normal es tan com√∫n
- Tabla de distribuciones: Caracter√≠sticas de cada distribuci√≥n
- Kernel Density Estimation (KDE): T√©cnica para estimar densidades
- Mixturas Gaussianas: Modelar distribuciones multimodales
- Entrop√≠a: Medida de incertidumbre en distribuciones

---

*Siguiente: [Pruebas de Hip√≥tesis](/wiki/pruebas-hipotesis)*
